{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxHZuxtfl7pusyBLCbKxII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiraGles/Machine-learning-traininng/blob/main/Evolutionary_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9D68ljBNF26W"
      },
      "outputs": [],
      "source": [
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV, maximize\n",
        "import sklearn.datasets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "import unittest\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def func(x, y, m=1.0, z=False):\n",
        "    return m * (np.exp(-(x ** 2 + y ** 2)) + float(z))\n",
        "\n",
        "\n",
        "def readme():\n",
        "    data = sklearn.datasets.load_digits()\n",
        "    X = data[\"data\"]\n",
        "    y = data[\"target\"]\n",
        "\n",
        "\n",
        "    paramgrid = {\n",
        "        \"kernel\": [\"rbf\"],\n",
        "        \"C\": np.logspace(-9, 9, num=25, base=10),\n",
        "        \"gamma\": np.logspace(-9, 9, num=25, base=10),\n",
        "    }\n",
        "\n",
        "    random.seed(1)\n",
        "\n",
        "    cv = EvolutionaryAlgorithmSearchCV(\n",
        "        estimator=SVC(),\n",
        "        params=paramgrid,\n",
        "        scoring=\"accuracy\",\n",
        "        cv=StratifiedKFold(n_splits=4),\n",
        "        verbose=1,\n",
        "        population_size=10,\n",
        "        gene_mutation_prob=0.10,\n",
        "        gene_crossover_prob=0.5,\n",
        "        tournament_size=3,\n",
        "        generations_number=5,\n",
        "    )\n",
        "\n",
        "    cv.fit(X, y)\n",
        "    return cv\n",
        "\n",
        "class TestEvolutionarySearch(unittest.TestCase):\n",
        "    def test_cv(self):\n",
        "        def try_with_params(**kwargs):\n",
        "            cv = readme()\n",
        "            cv_results_ = cv.cv_results_\n",
        "            print(\"CV Results:\\n{}\".format(cv_results_))\n",
        "            self.assertIsNotNone(cv_results_, msg=\"cv_results is None.\")\n",
        "            self.assertNotEqual(cv_results_, {}, msg=\"cv_results is empty.\")\n",
        "            self.assertAlmostEqual(\n",
        "                cv.best_score_,\n",
        "                1.0,\n",
        "                delta=0.05,\n",
        "                msg=\"Did not find the best score. Returned: {}\".format(cv.best_score_),\n",
        "            )\n",
        "\n",
        "        try_with_params()\n",
        "\n",
        "\n",
        "    def test_optimize(self):\n",
        "        \"\"\" Simple hill climbing optimization with some twists. \"\"\"\n",
        "\n",
        "        param_grid = {\"x\": [-1.0, 0.0, 1.0], \"y\": [-1.0, 0.0, 1.0], \"z\": [True, False]}\n",
        "        args = {\"m\": 1.0}\n",
        "\n",
        "        best_params, best_score, score_results, _, _ = maximize(\n",
        "            func, param_grid, args, verbose=True\n",
        "        )\n",
        "        print(\"Score Results:\\n{}\".format(score_results))\n",
        "\n",
        "        self.assertEqual(best_params, {\"x\": 0.0, \"y\": 0.0, \"z\": True})\n",
        "        self.assertEqual(best_score, 2.0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-genetic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TkiViTEGCMu",
        "outputId": "bcf320eb-714c-401b-f860-4dd60d926e60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-genetic\n",
            "  Downloading sklearn_genetic-0.5.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (0.70.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.21.5)\n",
            "Collecting deap>=1.0.2\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (3.1.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->sklearn-genetic) (0.3.4)\n",
            "Installing collected packages: deap, sklearn-genetic\n",
            "Successfully installed deap-1.3.1 sklearn-genetic-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqw9QbBsGCaM",
        "outputId": "bd033fd5-25f2-460a-d5a6-2ec5c8219acb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-deap\n",
            "  Downloading sklearn_deap-0.3.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: deap>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.3.1)\n",
            "Requirement already satisfied: scipy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sklearn-deap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sklearn-deap) (3.1.0)\n",
            "Installing collected packages: sklearn-deap\n",
            "Successfully installed sklearn-deap-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.datasets\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "data = sklearn.datasets.load_digits()\n",
        "X = data[\"data\"]\n",
        "y = data[\"target\"]\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "paramgrid = {\"kernel\": [\"rbf\"],\n",
        "             \"C\"     : np.logspace(-9, 9, num=25, base=10),\n",
        "             \"gamma\" : np.logspace(-9, 9, num=25, base=10)}\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "cv = EvolutionaryAlgorithmSearchCV(estimator=SVC(),\n",
        "                                   params=paramgrid,\n",
        "                                   scoring=\"accuracy\",\n",
        "                                   cv=StratifiedKFold(n_splits=4),\n",
        "                                   verbose=1,\n",
        "                                   population_size=50,\n",
        "                                   gene_mutation_prob=0.10,\n",
        "                                   gene_crossover_prob=0.5,\n",
        "                                   tournament_size=3,\n",
        "                                   generations_number=5,\n",
        "                                   n_jobs=4)\n",
        "cv.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4UeBMi5Ikol",
        "outputId": "85271f9e-ce60-4244-ed05-e4abe857b1a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Types [1, 2, 2] and maxint [0, 24, 24] detected\n",
            "--- Evolve in 625 possible combinations ---\n",
            "gen\tnevals\tavg    \tmin    \tmax     \tstd     \n",
            "0  \t50    \t0.24453\t0.10128\t0.968837\t0.311932\n",
            "1  \t36    \t0.44739\t0.10128\t0.971619\t0.403942\n",
            "2  \t23    \t0.769705\t0.101836\t0.971619\t0.337089\n",
            "3  \t31    \t0.948158\t0.148024\t0.971619\t0.114484\n",
            "4  \t30    \t0.934869\t0.10128 \t0.971619\t0.165466\n",
            "5  \t19    \t0.968948\t0.968837\t0.971619\t0.00054524\n",
            "Best individual is: {'kernel': 'rbf', 'C': 5.623413251903491, 'gamma': 0.00017782794100389227}\n",
            "with fitness: 0.9716193656093489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEVJY_AKThK",
        "outputId": "d68e8d6a-5208-4d10-ec58-89f673974d00"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Preprocessing\n",
            "  Downloading preprocessing-0.1.13-py3-none-any.whl (349 kB)\n",
            "\u001b[K     |████████████████████████████████| 349 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting nltk==3.2.4\n",
            "  Downloading nltk-3.2.4.tar.gz (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.0 MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme==0.2.4\n",
            "  Downloading sphinx_rtd_theme-0.2.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 22.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.2.4->Preprocessing) (1.15.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.4-py3-none-any.whl size=1367722 sha256=99a192fbafb7019f452e56e78146ad61b53765fdfd582d7c1a03aabd759cbdd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/5e/9e/4cb46185f2a16c60e6fc524372ba7fef89ce3347734c8798b6\n",
            "Successfully built nltk\n",
            "Installing collected packages: sphinx-rtd-theme, nltk, Preprocessing\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Preprocessing-0.1.13 nltk-3.2.4 sphinx-rtd-theme-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fifa_preprocessing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naoNwFVQLHSi",
        "outputId": "25320e81-e0fb-408b-a5d0-e267b83fa87a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fifa_preprocessing\n",
            "  Downloading fifa_preprocessing-1.1.2-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: fifa-preprocessing\n",
            "Successfully installed fifa-preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some bits of code I found that I may need eventually\n",
        "\n",
        "# KDE, https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/\n",
        "\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from scipy.stats import gaussian_kde\n",
        "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
        "\n",
        "def kde_scipy(x, x_grid, bandwidth=0.2, **kwargs):\n",
        "    \"\"\"Kernel Density Estimation with Scipy, use with small data\"\"\"\n",
        "    # Note that scipy weights its bandwidth by the covariance of the\n",
        "    # input data.  To make the results comparable to the other methods,\n",
        "    # we divide the bandwidth by the sample standard deviation here.\n",
        "    kde = gaussian_kde(x, bw_method=bandwidth / x.std(ddof=1), **kwargs)\n",
        "    return kde.evaluate(x_grid)    \n",
        "    \n",
        "def kde_statsmodels_m(x, x_grid, bandwidth=0.2, **kwargs):\n",
        "    \"\"\"Multivariate Kernel Density Estimation with Statsmodels, use with heterogeneous data\"\"\"\n",
        "    kde = KDEMultivariate(x, bw=bandwidth * np.ones_like(x),\n",
        "                          var_type='c', **kwargs)\n",
        "    return kde.pdf(x_grid)\n",
        "    \n",
        "def kde_sklearn(x, x_grid, bandwidth=0.2, **kwargs):\n",
        "    \"\"\"Kernel Density Estimation with Scikit-learn, use in general\"\"\"\n",
        "    kde_skl = KernelDensity(bandwidth=bandwidth, **kwargs)\n",
        "    kde_skl.fit(x[:, np.newaxis])\n",
        "    # score_samples() returns the log-likelihood of the samples\n",
        "    log_pdf = kde_skl.score_samples(x_grid[:, np.newaxis])\n",
        "    return np.exp(log_pdf)\n",
        "    \n",
        "    \n",
        "# ROC curves plotting, Yhat blog\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X, y = make_classification(n_samples=10000, n_features=10, n_classes=2, n_informative=5)\n",
        "Xtrain = X[:9000]\n",
        "Xtest = X[9000:]\n",
        "ytrain = y[:9000]\n",
        "ytest = y[9000:]\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from ggplot import *\n",
        "\n",
        "preds = clf.predict_proba(Xtest)[:,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(ytest, preds)\n",
        "\n",
        "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
        "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
        "    geom_line() +\\\n",
        "    geom_abline(linetype='dashed')\n",
        "\n",
        "auc = metrics.auc(fpr,tpr)\n",
        "ggplot(df, aes(x='fpr', ymin=0, ymax='tpr')) +\\\n",
        "    geom_area(alpha=0.2) +\\\n",
        "    geom_line(aes(y='tpr')) +\\\n",
        "    ggtitle(\"ROC Curve w/ AUC=%s\" % str(auc))\n",
        "\n",
        "\n",
        "# GridSearch in sklearn, from CS109\n",
        "# evolutionary algorithm to replace gridsearch from https://github.com/rsteca/sklearn-deap\n",
        "# Evolutionary not tested, may return wrong values\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "\n",
        "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None, evo=None, population_size=5):\n",
        "    if score_func:\n",
        "        if evo:\n",
        "            gs = EvolutionaryAlgorithmSearchCV(pipeline, grid=parameters, scoring=score_func, n_jobs=n_jobs, population_size=population_size)\n",
        "        else:\n",
        "            gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
        "    else:\n",
        "        if evo:\n",
        "            gs = EvolutionaryAlgorithmSearchCV(pipeline, grid=parameters, scoring=None, verbose=True, n_jobs=4, population_size=population_size)\n",
        "        else:\n",
        "            gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
        "    gs.fit(X, y)\n",
        "    print (\"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_)\n",
        "    best = gs.best_estimator_\n",
        "    return best\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://github.com/databricks/spark-sklearn\n",
        "from sklearn import grid_search, datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Use spark_sklearn’s grid search instead:\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from spark_sklearn import GridSearchCV\n",
        "digits = datasets.load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "param_grid = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"min_samples_split\": [1, 3, 10],\n",
        "              \"min_samples_leaf\": [1, 3, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"],\n",
        "              \"n_estimators\": [10, 20, 40, 80]}\n",
        "gs = grid_search.GridSearchCV(RandomForestClassifier(), param_grid=param_grid)\n",
        "gs.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "UrdEKxtTM2iD",
        "outputId": "93364d49-5118-47f1-a601-327468dd26e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-22070c64d9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ggplot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ggplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03cc5be2NFta",
        "outputId": "122bc290-dedc-4ba6-a81d-1d3c42aef75f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ggplot\n",
            "  Downloading ggplot-0.11.5-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting brewer2mpl\n",
            "  Downloading brewer2mpl-1.4.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.4 in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.5.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.11.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.10.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ggplot) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ggplot) (3.10.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ggplot) (2018.9)\n",
            "Installing collected packages: brewer2mpl, ggplot\n",
            "Successfully installed brewer2mpl-1.4.1 ggplot-0.11.5\n"
          ]
        }
      ]
    }
  ]
}